# Customer Churn Prediction: 
# A telecom company is losing customers. Your job is to predict who will leave so they can take preventive actions.

âœ… Load Customer Data: Identify key features (contract type, tenure, charges). 
âœ… Feature Engineering: Convert categorical variables (One-Hot Encoding).
âœ… Train Model: Logistic Regression (solver='saga' for large dataset).   
âœ… Evaluate: Precision, Recall, F1-score, Confusion Matrix.
âœ… Insights: What factors influence churn the most?. 
âœ… Visualize the predicted vs original.

# Learning Outcome: Business applications of classification models.

# Import libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix, precision_score,  recall_score, f1_score

# 1.Load Customer Data & Identify Key Features
df = pd.read_csv("customer_churn.csv")
print("First five rows:\n", df)
print("Dataset Info:\n", df.info()) # Check for missing values & datatypes

# Drop 'customerID' since it's just an identifier
df.drop(columns=['customerID'], inplace=True)

# Convert 'TotalCharges' to numeric (handling empty values)
df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')

# Fill missing numerical values with median
df.fillna(df.median(numeric_only=True), inplace=True)

# Identify categorical features (excluding 'Churn')
categorical_features = df.select_dtypes(include=['object']).columns.tolist()
categorical_features.remove('Churn')

# 2.Feature Engineering: One-Hot Encoding for Categorical Variables
df = pd.get_dummies(df, columns=categorical_features, drop_first=True)

# Convert target variable 'Churn' to binary format
df['Churn'] = df['Churn'].map({'Yes': 1, 'No': 0})

# Select Key Features for Training
X = df[['tenure', 'MonthlyCharges', 'TotalCharges'] + [col for col in df.columns if col.startswith('Contract_')]]
y = df['Churn']
print("After Encoded data:\n", df[['tenure', 'MonthlyCharges', 'TotalCharges', 'Churn']].head())

# Split into Train & Test Data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# Standardize Numeric Features
scaler = StandardScaler()
X_train[['tenure', 'MonthlyCharges', 'TotalCharges']] = scaler.fit_transform(X_train[['tenure', 'MonthlyCharges', 'TotalCharges']])
X_test[['tenure', 'MonthlyCharges', 'TotalCharges']] = scaler.transform(X_test[['tenure', 'MonthlyCharges', 'TotalCharges']])

# 3.Train Model: Logistic Regression
model = LogisticRegression(solver='saga', max_iter=5000)
model.fit(X_train, y_train)

# 4.Model Evaluation
y_pred = model.predict(X_test)
print("Accuracy:\n", accuracy_score(y_test, y_pred))
print("Classification Report:\n", classification_report(y_test, y_pred))

# Compute Precision, Recall, F1-score
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

print(f"\nðŸŽ¯ Precision: {precision:.4f}")
print(f"ðŸ“Œ Recall: {recall:.4f}")
print(f"ðŸ“Š F1-score: {f1:.4f}")

# Confusion Matrix
plt.figure(figsize=(5, 4))
sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt="d", cmap="Blues")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix")
plt.show()

# 5.Insights: Factors Influencing Churn
feature_importance = pd.DataFrame({'Feature': X.columns, 'Coefficient': model.coef_[0]})
feature_importance = feature_importance.sort_values(by='Coefficient', ascending=False)

# Plot Feature Importance
plt.figure(figsize=(10, 5))
sns.barplot(x=feature_importance['Coefficient'], y=feature_importance['Feature'])
plt.xlabel("Coefficient Value")
plt.ylabel("Feature")
plt.title("Feature Importance (Logistic Regression)")
plt.show()

# Scatter plot for predicted vs actual
plt.figure(figsize=(8, 6))
plt.scatter(y_test, y_pred, color='blue', alpha=0.5)
plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], 'r--', label='45-degree line')
plt.title('Predicted vs Actual values')
plt.xlabel('Actual')
plt.ylabel('Predicted')
plt.grid(True)
plt.show()

# Insights: What factors influence churn the most?
# Most Influential Factors: 
# Based on our data, the most influential factors are likely:
# 1.Contract Type (Two-year contracts reduce churn the most).
# 2.MonthlyCharges (High charges may increase churn).
# 3.TotalCharges (Long-term spending may reduce churn).

# Actionable Insights:
# 1.Offer discounts or incentives for longer contracts (e.g., two-year contracts).
# 2.Monitor and adjust pricing strategies to avoid high monthly charges.
# 3.Focus on customer satisfaction for long-term customers to reduce churn.
