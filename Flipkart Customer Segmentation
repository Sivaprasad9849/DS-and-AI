# Flipkart Customer - Segmentation
# Method: Clustering - K Means

# Step-1: Import libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans

# Step-2: Generate Customer data
customers = [
    "Aarav", "Vihaan", "Kabir", "Aryan", "Reyansh", "Aditi", "Ishita", "Kiara", "Meera", "Saanvi",
    "Ananya", "Rohan", "Neha", "Dev", "Tanvi", "Krishna", "Riya", "Siddharth", "Pooja", "Aakash"
]

df = pd.DataFrame({
    "Customer Name": customers,
    "Age": np.random.randint(18, 65, 20),
    "Annual Income (₹ L)": np.random.randint(3, 50, 20),
    "Spending Score (1-100)": np.random.randint(1, 101, 20),
})
df

# Step-3: Slect Features for Clustering
X = df[["Annual Income (₹ L)", "Spending Score (1-100)"]]
X

# Step-4: Plot the Elbow Method
# WCSS(Inertia) vs K(1 to 10)
# Compute WCSS (Within-Cluster Sum of Squares) for k=1 to k=10
wcss = []
for k in range(1, 11): #1, 2, 3, .....10
   kmeans = KMeans(n_clusters = k, random_state=42)
   # kmeans = KMeans(n_clusters = k, random_state=42, n_init=10)
   kmeans.fit(X)
   wcss.append(kmeans.inertia_)
   print("For", k, ":", wcss)

# Explanation:
# kmeans.inertia_ gives the sum of squared distances (SSD) of all points to their closest cluster centroid.
# wcss.append(kmeans.inertia_) stores this WCSS (inertia) value for each value of K in a list.
# This list is then used to plot the Elbow Curve, helping identify the optimal number of clusters.

# Plot WCSS vs K
plt.figure(figsize=(8, 5))
plt.plot(range(1, 11), wcss, marker = 'o', linestyle = '--', color = 'b')
plt.xlabel('Number of Clusters (k)')
plt.ylabel('WCSS (Inertia)')
plt.title('Elbow Method for Optimal K')
plt.grid(True)
plt.show()

# Step-5: Plot the data of flipkart customers
# Simple Scatter Plot
plt.figure(figsize = (10, 6))
plt.scatter(df["Annual Income (₹ L)"], df["Spending Score (1-100)"], color='blue', alpha=0.7)
plt.title("Income vs Spending Score")
plt.xlabel("Annual Income (₹ L)")
plt.ylabel("Spending Score (1-100)")
plt.grid(True)
plt.show()

# Step-6: Apply K-Means Clustering (K=3)
kmeans = KMeans(n_clusters = 3)
df['Cluster'] = kmeans.fit_predict(X)
df

# Step-7: Plot Clusters with Proper Colors and Labels
plt.figure(figsize=(8, 5))
colors = ["red", "blue", "green"]
for cluster in range(3): # cluster 0, 1, 2
    clustered_data = df[df['Cluster'] == cluster]
    plt.scatter(
        clustered_data["Annual Income (₹ L)"], clustered_data["Spending Score (1-100)"],
        color = colors[cluster], label = f"Cluster {cluster}", edgecolors = "black"
                )
plt.xlabel("Annual Income (₹ Lakhs)")
plt.ylabel("Spending Score (1-100)")
plt.title("Customer Segmentation (K-Means Clustering)")
plt.legend()
plt.show()

# Step-8: Names of customers on the customer data
plt.figure(figsize=(8, 5))
colors = ["red", "blue", "green"]
for cluster in range(3): # cluster 0, 1, 2
    clustered_data = df[df['Cluster'] == cluster]
    plt.scatter(
        clustered_data["Annual Income (₹ L)"], clustered_data["Spending Score (1-100)"],
        color = colors[cluster], label = f"Cluster {cluster}", edgecolors = "black"
                )
    # Label each point with customer name
    for i in range(len(clustered_data)):
        plt.text(clustered_data["Annual Income (₹ L)"].iloc[i], clustered_data["Spending Score (1-100)"].iloc[i],
                 clustered_data["Customer Name"].iloc[i], fontsize=9, verticalalignment="bottom")

plt.xlabel("Annual Income (₹ Lakhs)")
plt.ylabel("Spending Score (1-100)")
plt.title("Customer Segmentation (K-Means Clustering)")
plt.legend()
plt.show()
